# -*- coding: utf-8 -*-
"""music1010.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rRIbJWr5xqRW-jQfYN3R39QEIKsJgpUn
"""

from IPython.display import clear_output
import sys
import os
import math
import time
import glob
import datetime
import random
import pickle
import json
import numpy as np
from tqdm.notebook import tqdm
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.nn.utils import clip_grad_norm_
from torch.utils.data import Dataset, DataLoader
import shutil
# function to import all the functions in the main_cp
from main_cp import *

import os 
os.chdir('/home/marvin/storyteller/venv310_torch_cu118/src/music_creator/compound-word-transformer/workspace/uncond/cp-linear')

MODE = 'train'

###--- data ---###
path_data_root = './../../../dataset/representations/uncond/cp/ailab17k_from-scratch_cp'
path_train_data = os.path.join(path_data_root, 'train_data_linear.npz')
path_test_data = os.path.join(path_data_root, 'test_data_linear.npz')
path_dictionary =  os.path.join(path_data_root, 'dictionary.pkl')

###--- training config ---###
D_MODEL = 512
N_LAYER = 12
N_HEAD = 8
path_exp = './exp'
batch_size = 2
gid = 0
init_lr = 0.0001

max_grad_norm = 3
path_gendir = 'gen_midis'
num_songs = 5

init_lr = 0.0001

def get_train_data():
  dictionary = pickle.load(open(path_dictionary, 'rb'))
  event2word, word2event = dictionary
  train_data = np.load(path_train_data)
  return train_data, event2word, word2event, dictionary

def get_test_data():
  dictionary = pickle.load(open(path_dictionary, 'rb'))
  event2word, word2event = dictionary
  test_data = np.load(path_test_data)
  return test_data, event2word, word2event, dictionary




def generate(info_load_model):
    # path
    path_ckpt = info_load_model[0] # path to ckpt dir
    loss = info_load_model[1] # loss
    name = 'loss_' + str(loss)
    path_saved_ckpt = os.path.join(path_ckpt, name + '_params.pt')

    # load
    dictionary = pickle.load(open(path_dictionary, 'rb'))
    event2word, word2event = dictionary

    # outdir
    os.makedirs(path_gendir, exist_ok=True)

    # config
    n_class = []
    for key in event2word.keys():
        n_class.append(len(dictionary[0][key]))

    # init model
    net = TransformerModel(n_class, is_training=False)
    net.cuda()
    net.eval()
    
    # load model
    print('[*] load model from:',  path_saved_ckpt)
    net.load_state_dict(torch.load(path_saved_ckpt))

    # gen
    start_time = time.time()
    song_time_list = []
    words_len_list = []

    cnt_tokens_all = 0 
    sidx = 0
    while sidx < num_songs:
        try:
            start_time = time.time()
            print('current idx:', sidx)
            path_outfile = os.path.join(path_gendir, 'get_{}.mid'.format(str(sidx)))

            res = net.inference_from_scratch(dictionary)
            write_midi(res, path_outfile, word2event)

            song_time = time.time() - start_time
            word_len = len(res)
            print('song time:', song_time)
            print('word_len:', word_len)
            words_len_list.append(word_len)
            song_time_list.append(song_time)

            sidx += 1
        except KeyboardInterrupt:
            raise ValueError(' [x] terminated.')
        except:
            continue
  
    print('ave token time:', sum(words_len_list) / sum(song_time_list))
    print('ave song time:', np.mean(song_time_list))

    runtime_result = {
        'song_time':song_time_list,
        'words_len_list': words_len_list,
        'ave token time:': sum(words_len_list) / sum(song_time_list),
        'ave song time': float(np.mean(song_time_list)),
    }

    with open('runtime_stats.json', 'w') as f:
        json.dump(runtime_result, f)
info_load_model = info_load_model = ("./exp/",'32')
train(info_load_model = info_load_model , n_epoch = 50)

